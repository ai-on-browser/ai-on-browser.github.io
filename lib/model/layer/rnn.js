import Layer from"./base.js";import{Matrix,Tensor}from"../../util/math.js";export default class RNNLayer extends Layer{constructor({size:t,out_size:i=null,activation:s="tanh",recurrent_activation:_="sigmoid",return_sequences:h=!1,...r}){super(r),this._size=t,this._out_size=i||t,this._w_xh=null,this._w_hh=Matrix.randn(t,t),this._w_hy=Matrix.randn(t,this._out_size),this._b_xh=Matrix.zeros(1,t),this._b_hh=Matrix.zeros(1,t),this._b_hy=Matrix.zeros(1,this._out_size),this._z0=Matrix.zeros(1,this._out_size),this._rest=r,s&&(this._activation=this.network.getLayerFromName(s,r)),_&&(this._recurrent_activation=this.network.getLayerFromName(_,r)),this._return_sequences=h}calc(t){t=t.transpose(1,0,2),this._i=[];for(let i=0;i<t.sizes[0];i++)this._i[i]=t.at(i).toMatrix();this._w_xh||(this._w_xh=Matrix.randn(this._i[0].cols,this._size)),this._o=[],this._z=[],this._u=[],this._v=[];for(let t=0;t<this._i.length;t++){this._z[t]=this._i[t].dot(this._w_xh);const i=0===t?this._z0:this._z[t-1];this._z[t].add(i.dot(this._w_hh)),this._z[t].add(this._b_xh),this._z[t].add(this._b_hh),this._recurrent_activation&&(this._u[t]=this._z[t],this._z[t]=this._recurrent_activation.calc(this._z[t])),this._o[t]=this._z[t].dot(this._w_hy),this._o[t].add(this._b_hy),this._activation&&(this._v[t]=this._o[t],this._o[t]=this._activation.calc(this._o[t]))}if(this._return_sequences){return Tensor.fromArray(this._o.map((t=>t.toArray()))).transpose(1,0,2)}return this._o[this._o.length-1]}grad(t){return this._grad_bptt(t)}_grad_bptt(t){const i=this._o.length;if(this._bo=Array(i),this._return_sequences){t=t.transpose(1,0,2);for(let s=0;s<i;s++)this._bo[s]=t.at(s).toMatrix()}else this._bo[i-1]=t;this._activation&&(this._bo=this._bo.map(((t,i)=>t?(this._activation.calc(this._v[i]),this._activation.grad(t)):t))),this._bi=Array(i),this._bi[i-1]=this._bo[i-1].dot(this._w_hy.t),this._recurrent_activation&&(this._recurrent_activation.calc(this._u[i-1]),this._bi[i-1]=this._recurrent_activation.grad(this._bi[i-1]));for(let t=i-2;t>=0;t--)this._bi[t]=this._bi[t+1].dot(this._w_hh.t),this._bo[t]&&this._bi[t].add(this._bo[t].dot(this._w_hy.t)),this._recurrent_activation&&(this._recurrent_activation.calc(this._u[t]),this._bi[t]=this._recurrent_activation.grad(this._bi[t]));return Tensor.fromArray(this._bi.map((t=>t.toArray()))).transpose(1,0,2)}update(){this._update_bptt()}_update_bptt(){const t=this._o.length,i=Matrix.zeros(...this._w_xh.sizes),s=Matrix.zeros(1,this._size);for(let _=0;_<t;_++){const t=this._i[_].tDot(this._bi[_]);t.div(this._i[_].rows),i.add(t),s.add(this._bi[_].mean(0))}i.div(t),s.div(t),this._w_xh.sub(this._opt.delta("w_xh",i)),this._b_xh.sub(this._opt.delta("b_xh",s));const _=Matrix.zeros(this._size,this._size),h=Matrix.zeros(1,this._size);for(let i=0;i<t-1;i++){const t=this._z[i].tDot(this._bi[i+1]);t.div(this._z[i].rows),_.add(t),h.add(this._bi[i+1].mean(0))}_.div(t-1),h.div(t-1),this._w_hh.sub(this._opt.delta("w_hh",_)),this._b_hh.sub(this._opt.delta("b_hh",h));const r=Matrix.zeros(this._size,this._out_size),e=Matrix.zeros(1,this._out_size);for(let i=0;i<t;i++)if(this._bo[i]){const t=this._z[i].tDot(this._bo[i]);t.div(this._z[i].rows),r.add(t),e.add(this._bo[i].mean(0))}r.div(t),e.div(t),this._w_hy.sub(this._opt.delta("w_hy",r)),this._b_hy.sub(this._opt.delta("b_hy",e))}}
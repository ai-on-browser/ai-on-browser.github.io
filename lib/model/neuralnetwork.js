import Matrix from"../util/matrix.js";import Tensor from"../util/tensor.js";import{Layer,LossLayer}from"./layer/index.js";export{Layer}from"./layer/index.js";import InputLayer from"./layer/input.js";import OutputLayer from"./layer/output.js";export function NeuralnetworkException(t,e){this.message=t,this.value=e,this.name=NeuralnetworkException}export class Graph{constructor(){this._nodes=[]}get nodes(){return this._nodes}get size(){return this._nodes.length}static fromObject(t){const e=new Graph;for(const r of t){const t=Layer.fromObject(r);"string"==typeof r.input&&(r.input=[r.input]),e.add(t,r.name,r.input)}return e}toObject(){const t=[];for(let e=0;e<this._nodes.length;e++){const r=this._nodes[e],n=r.layer.toObject();r.name&&(n.name=r.name),r.input&&(n.input=r.input),t.push(n)}return t}add(t,e,r){let n=[];r?("string"==typeof r&&(r=[r]),n=r.map((t=>{const e=t&&t.match(/\[([0-9]+)\]$/),r=e?+e[1]:null,n=e?t.slice(0,-e[0].length):t;for(let t=0;t<this._nodes.length;t++)if(this._nodes[t].name===n)return{index:t,subscript:r};throw new NeuralnetworkException(`Unknown input name '${t}'.`)}))):this._nodes.length>0&&n.push({index:this._nodes.length-1,subscript:null}),this._nodes.push({layer:t,name:e,input:r,parents:n})}}export default class NeuralNetwork{static fromObject(t,e,r="sgd"){0===t.filter((t=>"output"===t.type)).length&&t.push({type:"output"}),e&&t.push({type:e});const n=new Set;for(const e of t)if(e.input&&Array.isArray(e.input))for(let t=0;t<e.input.length;t++)"number"==typeof e.input[t]&&(n.add(e.input[t]),e.input[t]=`__const_number_${e.input[t]}`);n.size&&(t[0].input=[]);const s=new Graph;for(const t of n){const e=Layer.fromObject({type:"const",value:t});s.add(e,`__const_number_${t}`,[])}let a=!1;for(const e of t){const t=Layer.fromObject(e);s.add(t,e.name,e.input),a||=t instanceof LossLayer}return a||s.add(new LossLayer({})),new NeuralNetwork(s,r)}constructor(t,e="sgd"){this._graph=t,this._optimizer=e,this._opt="adam"===e?new AdamOptimizer:"momentum"===e?new MomentumOptimizer:"rmsprop"===e?new RMSPropOptimizer:new SGDOptimizer,this._opt_managers=[];for(let t=0;t<this._graph.size;t++)this._opt_managers.push(this._opt.manager())}copy(){return new NeuralNetwork(Graph.fromObject(this._graph.toObject()),this._optimizer)}toObject(){return this._graph.toObject()}calc(t,e,r,n={}){let s=0;if(Array.isArray(t))2===(t=Tensor.fromArray(t)).dimension&&(t=t.toMatrix()),s=t.sizes[0];else if(t instanceof Matrix||t instanceof Tensor)s=t.sizes[0];else for(const e of Object.keys(t))t[e]=Tensor.fromArray(t[e]),2===t[e].dimension&&(t[e]=t[e].toMatrix()),s=t[e].sizes[0];for(const r of this._graph.nodes)r.layer.bind({input:t,supervisor:e,n:s,...n});const a=[],i={};for(let t=0;t<this._graph.size;t++){const n=this._graph.nodes[t];if(a[t]=n.layer.calc(...n.parents.map((t=>null!==t.subscript?a[t.index][t.subscript]:a[t.index]))),r&&r.indexOf(n.name)>=0&&(i[n.name]=a[t],Object.keys(i).length===r.length))return i;if(!e&&n.layer instanceof OutputLayer)return r?i:a[t]}return r?i:a[a.length-1]}grad(t){const e=[];let r=null;for(let t=0;t<this._graph.size;e[t++]=[]);for(let n=this._graph.size-1;n>=0;n--){const s=this._graph.nodes[n];if(t){if(!(s.layer instanceof OutputLayer))continue;e[n]=[t],t=null}if(!(s.layer instanceof LossLayer)&&0===e[n].length)continue;for(let t=0;t<e[n].length;t++)void 0===e[n][t]&&(e[n][t]=null);let a=s.layer.grad(...e[n]);Array.isArray(a)||(a=Array(s.parents.length).fill(a)),s.parents.forEach(((t,r)=>{if(!a[r])return;const n=t.subscript||0;e[t.index][n]?e[t.index][n].add(a[r]):e[t.index][n]=a[r].copy()})),s.layer instanceof InputLayer&&(r=e[n][0])}return r}update(t){this._opt.learningRate=t;for(let t=0;t<this._graph.size;t++)this._graph.nodes[t].layer.update(this._opt_managers[t])}fit(t,e,r=1,n=.1,s=null,a={}){if(Array.isArray(t))2===(t=Tensor.fromArray(t)).dimension&&(t=t.toMatrix());else if(!(t instanceof Matrix||t instanceof Tensor))for(const e of Object.keys(t))t[e]=Tensor.fromArray(t[e]),2===t[e].dimension&&(t[e]=t[e].toMatrix());let i;for(e=Matrix.fromArray(e);r-- >0;)if(s)for(let r=0;r<e.rows;r+=s){const o=Math.min(e.rows,r+s);let p;if(t instanceof Matrix||t instanceof Tensor)p=t.slice(r,o);else{p={};for(const e of Object.keys(t))p[e]=(t[e],t[e].slice(r,o))}i=this.calc(p,e.slice(r,o),null,a),this.grad(),this.update(n)}else i=this.calc(t,e,null,a),this.grad(),this.update(n);return i.toArray().flat()}predict(t){return this.calc(t).toArray()}}class SGDOptimizer{constructor(t){this._learningrate=t}set learningRate(t){this._learningrate=t}manager(){const t=this;return{get lr(){return t._learningrate},delta(t,e){return e.copyMult(this.lr)}}}}class MomentumOptimizer{constructor(t,e=.9){this._learningrate=t,this._beta=e}set learningRate(t){this._learningrate=t}manager(){const t=this;return{get lr(){return t._learningrate},params:{},delta(e,r){if(!this.params[e])return this.params[e]=r,r.copyMult(this.lr);const n=this.params[e].copyMult(t._beta);return n.add(r.copyMult(1-t._beta)),this.params[e]=n,n.copyMult(this.lr)}}}}class RMSPropOptimizer{constructor(t,e=.999){this._learningrate=t,this._beta=e}set learningRate(t){this._learningrate=t}manager(){const t=this;return{get lr(){return t._learningrate},params:{},delta(e,r){if(!this.params[e])return this.params[e]=r.copyMult(r),r.copyMult(this.lr);const n=this.params[e].copyMult(t._beta);return n.add(r.copyMap((e=>(1-t._beta)*e*e))),this.params[e]=n,r.copyMult(n.copyMap((t=>this.lr/Math.sqrt(t+1e-12))))}}}}class AdamOptimizer{constructor(t=.001,e=.9,r=.999){this._learningrate=t,this._beta1=e,this._beta2=r}set learningRate(t){this._learningrate=t}manager(){const t=this;return{get lr(){return t._learningrate},params:{},delta(e,r){if(!this.params[e])return this.params[e]={v:r,s:r.copyMult(r)},r.copyMult(this.lr);const n=this.params[e].v.copyMult(t._beta1);n.add(r.copyMult(1-t._beta1));const s=this.params[e].s.copyMult(t._beta2);return s.add(r.copyMap((e=>(1-t._beta2)*e*e))),this.params[e]={v:n,s:s},n.copyMult(s.copyMap((t=>this.lr/Math.sqrt(t+1e-12))))}}}}
import{Tensor,Matrix}from"../util/math.js";function NeuralnetworkException(t,s){this.message=t,this.value=s,this.name=NeuralnetworkException}export default class NeuralNetwork{constructor(t,s,e="sgd"){this._request_layer=t,this._layers=[],0===t.filter((t=>"output"===t.type)).length&&t.push({type:"output"}),s&&t.push({type:s});const r=new Set;for(const s of t)if(s.input&&Array.isArray(s.input))for(let t=0;t<s.input.length;t++)"number"==typeof s.input[t]&&(r.add(s.input[t]),s.input[t]=`__const_number_${s.input[t]}`);r.size&&(t[0].input=[]),this._optimizer=e,this._opt="adam"===e?new AdamOptimizer:"momentum"===e?new MomentumOptimizer:"rmsprop"===e?new RMSPropOptimizer:new SGDOptimizer;for(const t of r){const s=new NeuralnetworkLayers.const({value:t,size:1,input:[]});s.network=this,s.name=`__const_number_${t}`,s.parent=[],this._layers.push(s)}for(const s of t){if(!NeuralnetworkLayers[s.type])throw`Invalid layer type ${s.type}.`;const t=new NeuralnetworkLayers[s.type]({...s,optimizer:this._opt.manager()});if(t.network=this,t.name=s.name,t.parent=[],t.input=s.input,s.input){"string"==typeof s.input&&(s.input=[s.input]);for(const e of s.input){const s=/\[([0-9]+)\]$/,r=e&&e.match(s),i=r?+r[1]:null,a=r?e.slice(0,-r[0].length):e,n=this._layers.filter((t=>a===t.name));t.parent.push({layer:n[0],index:this._layers.indexOf(n[0]),subscript:i})}}else{const s=this._layers.length-1;s>=0&&t.parent.push({layer:this._layers[s],index:s,subscript:null})}this._layers.push(t)}}copy(){const t=new NeuralNetwork(this._request_layer,null,this._optimizer);for(let s=0;s<this._layers.length;s++)t._layers[s].set_params(this._layers[s].get_params());return t}calc(t,s,e,r={}){let i=0;if(Array.isArray(t))2===(t=Tensor.fromArray(t)).dimension&&(t=t.toMatrix()),i=t.sizes[0];else if(t instanceof Matrix||t instanceof Tensor)i=t.sizes[0];else for(const s of Object.keys(t))t[s]=Tensor.fromArray(t[s]),2===t[s].dimension&&(t[s]=t[s].toMatrix()),i=t[s].sizes[0];for(const e of this._layers)e.bind({input:t,supervisor:s,n:i,...r});const a=[],n={};for(let t=0;t<this._layers.length;t++){const r=this._layers[t];if(a[t]=r.calc(...r.parent.map((t=>null!==t.subscript?a[t.index][t.subscript]:a[t.index]))),e&&e.indexOf(r.name)>=0&&(n[r.name]=a[t],Object.keys(n).length===e.length))return n;if(!s&&r instanceof NeuralnetworkLayers.output)return e?n:a[t]}return e?n:a[a.length-1]}grad(t){const s=[];let e=null;for(let t=0;t<this._layers.length;s[t++]=[]);s[s.length-1]=[new Matrix(1,1,1)];for(let r=this._layers.length-1;r>=0;r--){const i=this._layers[r];if(t){if(!(i instanceof NeuralnetworkLayers.output))continue;s[r]=[t],t=null}if(0===s[r].length)continue;let a=i.grad(...s[r]);Array.isArray(a)||(a=Array(i.parent.length).fill(a)),i.parent.forEach(((t,e)=>{if(!a[e])return;const r=t.subscript||0;s[t.index][r]?s[t.index][r].add(a[e]):s[t.index][r]=a[e].copy()})),i instanceof NeuralnetworkLayers.input&&(e=s[r][0])}return e}update(t){this._opt.learningRate=t;for(let t=0;t<this._layers.length;t++)this._layers[t].update()}fit(t,s,e=1,r=.1,i=null,a={}){if(Array.isArray(t))2===(t=Tensor.fromArray(t)).dimension&&(t=t.toMatrix());else if(!(t instanceof Matrix||t instanceof Tensor))for(const s of Object.keys(t))t[s]=Tensor.fromArray(t[s]),2===t[s].dimension&&(t[s]=t[s].toMatrix());let n;for(s=Matrix.fromArray(s);e-- >0;)if(i)for(let e=0;e<s.rows;e+=i){const o=Math.min(s.rows,e+i);let l;if(t instanceof Matrix||t instanceof Tensor)l=t instanceof Matrix?t.sliceRow(e,o):t.slice(e,o);else{l={};for(const s of Object.keys(t))l[s]=t[s]instanceof Matrix?t[s].sliceRow(e,o):t[s].slice(e,o)}n=this.calc(l,s.sliceRow(e,o),null,a),this.grad(),this.update(r)}else n=this.calc(t,s,null,a),this.grad(),this.update(r);return n.value}}class SGDOptimizer{constructor(t){this._learningrate=t}set learningRate(t){this._learningrate=t}manager(){const t=this;return{get lr(){return t._learningrate},delta(t,s){return s.copyMult(this.lr)}}}}class MomentumOptimizer{constructor(t,s=.9){this._learningrate=t,this._beta=s}set learningRate(t){this._learningrate=t}manager(){const t=this;return{get lr(){return t._learningrate},params:{},delta(s,e){if(!this.params[s])return this.params[s]=e,e.copyMult(this.lr);const r=this.params[s].copyMult(t._beta);return r.add(e.copyMult(1-t._beta)),this.params[s]=r,r.copyMult(this.lr)}}}}class RMSPropOptimizer{constructor(t,s=.999){this._learningrate=t,this._beta=s}set learningRate(t){this._learningrate=t}manager(){const t=this;return{get lr(){return t._learningrate},params:{},delta(s,e){if(!this.params[s])return this.params[s]=e.copyMult(e),e.copyMult(this.lr);const r=this.params[s].copyMult(t._beta);return r.add(e.copyMap((s=>(1-t._beta)*s*s))),this.params[s]=r,e.copyMult(r.copyMap((t=>this.lr/Math.sqrt(t+1e-12))))}}}}class AdamOptimizer{constructor(t=.001,s=.9,e=.999){this._learningrate=t,this._beta1=s,this._beta2=e}set learningRate(t){this._learningrate=t}manager(){const t=this;return{get lr(){return t._learningrate},params:{},delta(s,e){if(!this.params[s])return this.params[s]={v:e,s:e.copyMult(e)},e.copyMult(this.lr);const r=this.params[s].v.copyMult(t._beta1);r.add(e.copyMult(1-t._beta1));const i=this.params[s].s.copyMult(t._beta2);return i.add(e.copyMap((s=>(1-t._beta2)*s*s))),this.params[s]={v:r,s:i},r.copyMult(i.copyMap((t=>this.lr/Math.sqrt(t+1e-12))))}}}}const NeuralnetworkLayers={};class Layer{constructor({optimizer:t=null}){this._opt=t}bind(t){}calc(t){throw new NeuralnetworkException("Not impleneted",this)}grad(t){throw new NeuralnetworkException("Not impleneted",this)}update(){}get_params(){return null}set_params(t){}}NeuralnetworkLayers.input=class extends Layer{constructor({name:t=null,...s}){super(s),this._name=t}bind({input:t}){if(t instanceof Matrix||t instanceof Tensor)this._o=t;else{if(!t||!t[this._name])throw new NeuralnetworkException("Invalid input.",[this,t]);this._o=t[this._name]}}calc(){return this._o}grad(t){}},NeuralnetworkLayers.output=class extends Layer{calc(t){return t}grad(t){return t}},NeuralnetworkLayers.supervisor=class extends Layer{bind({supervisor:t}){t instanceof Matrix&&(this._o=t)}calc(){return this._o}grad(t){}},NeuralnetworkLayers.include=class extends Layer{constructor({id:t=null,net:s=null,input_to:e=null,train:r=!0,...i}){super(i),this._id=t,this._input_to=e,this._model=s||self.model[t],this._train=r,this._org_i=null,this._org_t=null}bind({input:t,supervisor:s}){this._org_i=t,this._org_t=s}calc(t){if(!(this._org_i instanceof Matrix)&&this._input_to){const s=t;(t=this._org_i)[this._input_to]=s}return this._model.calc(t)}grad(t){return this._model.grad(t)}update(){this._train&&this._model.update(this._opt.lr)}},NeuralnetworkLayers.const=class extends Layer{constructor({value:t,...s}){super(s),this._value=t}calc(){return new Matrix(1,1,this._value)}grad(t){}},NeuralnetworkLayers.random=class extends Layer{constructor({size:t,...s}){super(s),this._size=t,this._rows=1}bind({n:t}){this._rows=t}calc(){return Matrix.randn(this._rows,this._size)}grad(t){}},NeuralnetworkLayers.variable=class extends Layer{constructor({size:t,l2_decay:s=0,l1_decay:e=0,...r}){super(r),this._size=t,this._v=Matrix.randn(t[0],t[1]),this._l2_decay=s,this._l1_decay=e,this._n=1}bind({n:t}){this._n=t}calc(){return this._v}grad(t){this._bo=t}update(){const t=this._bo.copyDiv(this._n);if(this._l2_decay>0||this._l1_decay>0)for(let s=0;s<this._v.rows;s++)for(let e=0;e<this._v.cols;e++){const r=this._v.at(s,e);t.addAt(s,e,r*this._l2_decay+Math.sign(r)*this._l1_decay)}this._v.sub(this._opt.delta("v",t))}get_params(){return{v:this._v}}set_params(t){this._v=t.v.copy()}},NeuralnetworkLayers.full=class extends Layer{constructor({in_size:t=null,out_size:s,activation:e=null,l2_decay:r=0,l1_decay:i=0,...a}){super(a),this._in_size=t,this._out_size=s,this._w=null,this._b=Matrix.randn(1,s),e&&(this._activation_func=new NeuralnetworkLayers[e](a)),this._l2_decay=r,this._l1_decay=i}calc(t){return this._w||(this._w=Matrix.randn(t.cols,this._out_size)),this._i=t,this._o=t.dot(this._w),this._o.add(this._b),this._activation_func?this._activation_func.calc(this._o):this._o}grad(t){return this._bo=t,this._activation_func&&(this._bo=this._activation_func.grad(t)),this._bi=this._bo.dot(this._w.t),this._bi}update(){const t=this._i.tDot(this._bo);if(t.div(this._i.rows),this._l2_decay>0||this._l1_decay>0)for(let s=0;s<t.rows;s++)for(let e=0;e<t.cols;e++){const r=this._w.at(s,e);t.addAt(s,e,r*this._l2_decay+Math.sign(r)*this._l1_decay)}this._w.sub(this._opt.delta("w",t));const s=this._bo.sum(0);s.div(this._i.rows),this._b.sub(this._opt.delta("b",s))}get_params(){return{w:this._w,b:this._b}}set_params(t){this._w=t.w.copy(),this._b=t.b.copy()}},NeuralnetworkLayers.linear=class extends Layer{calc(t){return t}grad(t){return t}},NeuralnetworkLayers.negative=class extends Layer{calc(t){return t.copyMult(-1)}grad(t){return t.copyMult(-1)}},NeuralnetworkLayers.sigmoid=class extends Layer{constructor({a:t=1,...s}){super(s),this._a=t}calc(t){return this._o=t.copyMap((t=>1/(1+Math.exp(-this._a*t)))),this._o}grad(t){const s=this._o.copyMap((t=>t*(1-t)));return s.mult(t),s}},NeuralnetworkLayers.tanh=class extends Layer{calc(t){return this._i=t,t.copyMap(Math.tanh)}grad(t){const s=this._i.copyMap((t=>1/Math.cosh(t)**2));return s.mult(t),s}},NeuralnetworkLayers.softsign=class extends Layer{calc(t){return this._i=t,t.copyMap((t=>t/(1+Math.abs(t))))}grad(t){const s=this._i.copyMap((t=>1/(1+Math.abs(t))**2));return s.mult(t),s}},NeuralnetworkLayers.softplus=class extends Layer{calc(t){return this._i=t,t.copyMap((t=>Math.log(1+Math.exp(t))))}grad(t){const s=this._i.copyMap((t=>1/(1+Math.exp(-t))));return s.mult(t),s}},NeuralnetworkLayers.abs=class extends Layer{calc(t){return this._i=t,this._o=t.copyMap(Math.abs),this._o}grad(t){const s=this._i.copyMap((t=>t<0?-1:1));return s.mult(t),s}},NeuralnetworkLayers.relu=class extends Layer{calc(t){return this._o=t.copyMap((t=>t>0?t:0)),this._o}grad(t){const s=this._o.copyMap((t=>t>0?1:0));return s.mult(t),s}},NeuralnetworkLayers.leaky_relu=class extends Layer{constructor({a:t=.1,...s}){super(s),this._a=t}calc(t){return this._o=t.copyMap((t=>t>0?t:t*this._a)),this._o}grad(t){const s=this._o.copyMap((t=>t>0?1:this._a));return s.mult(t),s}},NeuralnetworkLayers.softmax=class extends Layer{calc(t){return this._o=t.copyMap(Math.exp),this._o.div(this._o.sum(1)),this._o}grad(t){this._bi=new Matrix(t.rows,t.cols);for(let s=0;s<t.rows;s++)for(let e=0;e<t.cols;e++){const r=this._o.at(s,e);let i=0;for(let a=0;a<t.cols;a++){const n=e===a?1-r:-r;i+=this._o.at(s,a)*n*t.at(s,a)}this._bi.set(s,e,i)}return this._bi}},NeuralnetworkLayers.log=class extends Layer{calc(t){return this._i=t,t.copyMap(Math.log)}grad(t){const s=this._i.copyMap((t=>1/t));return s.mult(t),s}},NeuralnetworkLayers.exp=class extends Layer{calc(t){return this._o=t.copyMap(Math.exp),this._o}grad(t){return this._o.copyMult(t)}},NeuralnetworkLayers.square=class extends Layer{calc(t){return this._i=t,t.copyMult(t)}grad(t){const s=this._i.copyMult(2);return s.mult(t),s}},NeuralnetworkLayers.sqrt=class extends Layer{calc(t){return this._i=t,this._o=t.copyMap(Math.sqrt),this._o}grad(t){const s=this._o.copyMap((t=>1/(2*t)));return s.mult(t),s}},NeuralnetworkLayers.power=class extends Layer{constructor({n:t,...s}){super(s),this._n=t}calc(t){return this._i=t,t.copyMap((t=>t**this._n))}grad(t){const s=this._i.copyMap((t=>this._n*t**(this._n-1)));return s.mult(t),s}},NeuralnetworkLayers.gaussian=class extends Layer{calc(t){return this._i=t,this._o=t.copyMap((t=>Math.exp(-t*t/2))),this._o}grad(t){const s=this._o.copyMult(this._i);return s.mult(-1),s.mult(t),s}},NeuralnetworkLayers.sparsity=class extends Layer{constructor({rho:t,beta:s,...e}){super(e),this._rho=t,this._beta=s}bind({rho:t}){this._rho=t||this._rho}calc(t){return this._rho_hat=t.mean(0),t}grad(t){const s=this._rho_hat.copyIdiv(-this._rho);return s.add(this._rho_hat.copyIsub(1).copyIdiv(1-this._rho)),s.mult(this._beta),t.copyAdd(s)}},NeuralnetworkLayers.dropout=class extends Layer{constructor({drop_rate:t=.5,...s}){super(s),this._drop_rate=t}_shuffle(t){const s=Array(t);for(let e=0;e<t;s[e]=e++);for(let e=t-1;e>0;e--){let t=Math.floor(Math.random()*(e+1));[s[e],s[t]]=[s[t],s[e]]}return s.slice(0,Math.max(1,Math.floor(t*this._drop_rate)))}calc(t){this._drop_index=this._shuffle(t.cols);const s=t.copy();for(let e=0;e<t.rows;e++)for(const t of this._drop_index)s.set(e,t,0);return s}grad(t){const s=t.copy();for(let e=0;e<t.rows;e++)for(const t of this._drop_index)s.set(e,t,0);return s}},NeuralnetworkLayers.clip=class extends Layer{constructor({min:t=null,max:s=null,...e}){super(e),this._min=t,this._max=s}calc(t){const s=t.copy();return s.map((t=>null!==this._min&&t<this._min?this._min:null!==this._max&&t>this._max?this._max:t)),s}grad(t){return t}},NeuralnetworkLayers.add=class extends Layer{calc(...t){this._sizes=t.map((t=>t.sizes));let s=t[0].copy();for(let e=1;e<t.length;e++)s.add(t[e]);return s}grad(t){const s=t.sizes;return this._sizes.map((e=>{if(s.map(((t,s)=>t/e[s])).every((t=>1===t)))return t;const r=Matrix.zeros(e[0],e[1]);for(let i=0;i<s[0];i++)for(let a=0;a<s[1];a++)r.addAt(i%e[0],a%e[1],t.at(i,a));return r}))}},NeuralnetworkLayers.sub=class extends Layer{calc(...t){this._sizes=t.map((t=>t.sizes));let s=t[0].copy();for(let e=1;e<t.length;e++)s.sub(t[e]);return s}grad(t){const s=t.copyMap((t=>-t));return this._sizes.map(((e,r)=>{const i=0===r?t:s;if(i.sizes.map(((t,s)=>t/e[s])).every((t=>1===t)))return i;const a=Matrix.zeros(e[0],e[1]);for(let t=0;t<i.sizes[0];t++)for(let s=0;s<i.sizes[1];s++)a.addAt(t%e[0],s%e[1],i.at(t,s));return a}))}},NeuralnetworkLayers.mult=class extends Layer{calc(...t){this._i=t;let s=t[0].copy();for(let e=1;e<t.length;e++)s.mult(t[e]);return s}grad(t){return this._i.map(((s,e)=>{const r=s.sizes,i=t.copy();for(let t=0;t<this._i.length;t++)e!==t&&i.mult(this._i[t]);if(i.sizes.map(((t,s)=>t/r[s])).every((t=>1===t)))return i;const a=Matrix.zeros(r[0],r[1]);for(let t=0;t<i.sizes[0];t++)for(let s=0;s<i.sizes[1];s++)a.addAt(t%r[0],s%r[1],i.at(t,s));return a}))}},NeuralnetworkLayers.div=class extends Layer{calc(...t){this._i=t,this._den=t[1].copy();for(let s=2;s<t.length;s++)this._den.mult(t[s]);return t[0].copyDiv(this._den)}grad(t){const s=this._i[0].copyMult(-1);return s.div(this._den),s.div(this._den),s.mult(t),this._i.map(((e,r)=>{const a=e.sizes;let n;if(0===r)n=t.copyDiv(this._den);else{n=s.copy();for(let t=1;t<this._i.length;t++)i!==t&&n.mult(this._i[t])}if(n.sizes.map(((t,s)=>t/a[s])).every((t=>1===t)))return n;const o=Matrix.zeros(a[0],a[1]);for(let t=0;t<n.sizes[0];t++)for(let s=0;s<n.sizes[1];s++)o.addAt(t%a[0],s%a[1],n.at(t,s));return o}))}},NeuralnetworkLayers.matmul=class extends Layer{calc(...t){this._i=t;let s=t[0];for(let e=1;e<t.length;e++)s=s.dot(t[e]);return s}grad(t){const s=[];for(let e=0;e<this._i.length;e++){let r=null;if(0===e)r=t;else{r=this._i[0];for(let t=1;t<e;t++)r=r.dot(this._i[t]);r=r.tDot(t)}for(let t=this._i.length-1;t>e;t--)r.dot(this._i[t].t);s.push(r)}return s}},NeuralnetworkLayers.conv=class extends Layer{constructor({kernel:t,channel:s=null,stride:e=null,padding:r=null,activation:i=null,l2_decay:a=0,l1_decay:n=0,...o}){super(o),this._in_channel=null,this._out_channel=s,this._kernel=t,this._stride=e||1,this._padding=r||0,this._w=null,i&&(this._activation_func=new NeuralnetworkLayers[i](o)),this._l2_decay=a,this._l1_decay=n}calc(t){if(Array.isArray(this._kernel)||(this._kernel=Array(t.dimension-2).fill(this._kernel)),t.dimension!==this._kernel.length+2)throw new NeuralnetworkException("Invalid kernel size",[this,t]);this._w||(this._in_channel=t.sizes[t.dimension-1],this._out_channel||(this._out_channel=2*this._in_channel),this._w=Tensor.randn([this._in_channel,...this._kernel,this._out_channel])),this._i=t;const s=[t.sizes[0],...this._kernel.map(((s,e)=>Math.ceil((t.sizes[e+1]+2*this._padding)/this._stride)+1-s)),this._out_channel];this._o=new Tensor(s);for(let e=0;e<t.sizes[0];e++)for(let r=0;r<this._in_channel;r++)for(let i=0;i<this._out_channel;i++){if(2!==this._kernel.length)throw new NeuralnetworkException("Invalid dimension.");for(let a=0;a<s[1];a++)for(let n=0;n<s[2];n++){let s=0;for(let o=0;o<this._kernel[0];o++)if(!(a-this._padding+o<0||a-this._padding+o>=t.sizes[1]))for(let l=0;l<this._kernel[1];l++)n-this._padding+l<0||n-this._padding+l>=t.sizes[2]||(s+=t.at(e,a-this._padding+o,n-this._padding+l,r)*this._w.at(r,o,l,i));this._o.set([e,a,n,i],s)}}return this._activation_func?this._activation_func.calc(this._o):this._o}grad(t){this._bo=t,this._activation_func&&(this._bo=this._activation_func.grad(t)),this._bi=new Tensor(this._i.sizes),this._dw=new Tensor(this._w.sizes);for(let s=0;s<this._i.sizes[0];s++)for(let e=0;e<this._in_channel;e++)for(let r=0;r<this._out_channel;r++){if(2!==this._kernel.length)throw new NeuralnetworkException("Invalid dimension.");for(let i=0;i<t.sizes[1];i++)for(let a=0;a<t.sizes[2];a++)for(let n=0;n<this._kernel[0];n++){const o=i-this._padding+n;if(!(o<0||o>=this._i.sizes[1]))for(let l=0;l<this._kernel[1];l++){const h=a-this._padding+l;if(h<0||h>=this._i.sizes[2])continue;const c=this._bi.at(s,o,h,e);this._bi.set([s,o,h,e],c+this._w.at(e,n,l,r)*t.at(s,i,a,r));const _=this._dw.at(e,n,l,r);this._dw.set([e,n,l,r],_+this._i.at(s,o,h,e)*this._bo.at(s,i,a,r))}}}return this._bi}update(){this._dw.reshape(this._dw.sizes[0],this._dw.length/this._dw.sizes[0]);const t=this._opt.delta("w",this._dw.toMatrix());for(let s=0;s<this._w.length;s++)this._w.value[s]-=t.value[s]}get_params(){return{w:this._w}}set_params(t){this._w=t.w.copy()}},NeuralnetworkLayers.sum=class extends Layer{constructor({axis:t=-1,...s}){super(s),this._axis=t}calc(t){return this._i=t,this._axis<0?new Matrix(1,1,t.sum()):t.sum(this._axis)}grad(t){return this._axis<0?new Matrix(this._i.rows,this._i.cols,t.value[0]):t.copyRepeat(this._i.sizes[this._axis],this._axis)}},NeuralnetworkLayers.mean=class extends Layer{constructor({axis:t=-1,...s}){super(s),this._axis=t}calc(t){return this._i=t,this._axis<0?new Matrix(1,1,t.mean()):t.mean(this._axis)}grad(t){if(this._axis<0)return new Matrix(this._i.rows,this._i.cols,t.value[0]/this._i.length);const s=t.copyRepeat(this._i.sizes[this._axis],this._axis);return s.div(this._i.sizes[this._axis]),s}},NeuralnetworkLayers.variance=class extends Layer{constructor({axis:t=-1,...s}){super(s),this._axis=t}calc(t){return this._i=t,this._m=t.mean(this._axis),this._axis<0?new Matrix(1,1,t.variance()):t.variance(this._axis)}grad(t){if(this._axis<0)return this._i.copyMap((t=>2*(t-this._m)/this._i.length));const s=this._i.copySub(this._m);return s.mult(2/this._i.sizes[this._axis]),s.mult(t),s}},NeuralnetworkLayers.reshape=class extends Layer{constructor({size:t,...s}){super(s),this._size=t}calc(t){this._in_size=t.sizes.concat(),this._out_size=[t.sizes[0],...this._size];const s=2===this._out_size.length?t.copy():Tensor.fromArray(t.copy());return s.reshape(...this._out_size),s instanceof Tensor&&2===s.dimension?s.toMatrix():s}grad(t){let s=t.copy();return s instanceof Matrix&&this._in_size.length>2&&(s=Tensor.fromArray(s)),s.reshape(...this._in_size),s}},NeuralnetworkLayers.transpose=class extends Layer{constructor({axis:t,...s}){super(s),this._axis=t}calc(t){return t.transpose(...this._axis)}grad(t){const s=[];for(let t=0;t<this._axis.length;t++)s.push(this._axis.indexOf(t));return t.transpose(...s)}},NeuralnetworkLayers.flatten=class extends Layer{calc(t){if(this._in_size=t.sizes.concat(),t instanceof Matrix)return t;const s=t.copy();return s.reshape(s.sizes[0],s.length/s.sizes[0]),s.toMatrix()}grad(t){if(2===this._in_size.length)return t;const s=Tensor.fromArray(t.copy());return s.reshape(...this._in_size),s}},NeuralnetworkLayers.concat=class extends Layer{constructor({axis:t=1,...s}){super(s),this._axis=t}calc(...t){let s=t[0],e=t[0].sizes[this._axis];this._sizes=[0,e];for(let r=1;r<t.length;r++)s=s.concat(t[r],this._axis),this._sizes.push(e+=t[r].sizes[this._axis]);return s}grad(t){const s=[];for(let e=0;e<this._sizes.length-1;e++)1===this._axis?s.push(t.sliceCol(this._sizes[e],this._sizes[e+1])):s.push(t.sliceRow(this._sizes[e],this._sizes[e+1]));return s}},NeuralnetworkLayers.split=class extends Layer{constructor({axis:t=1,size:s,...e}){super(e),this._axis=t,this._size=s}calc(t){let s=0;const e=[];for(let r=0;r<this._size.length;r++)1===this._axis?e.push(t.sliceCol(s,s+this._size[r])):e.push(t.sliceRow(s,s+this._size[r])),s+=this._size[r];return e}grad(...t){let s=t[0];for(let e=1;e<t.length;e++)s=s.concat(t[e],this._axis);return s}},NeuralnetworkLayers.onehot=class extends Layer{constructor({class_size:t=null,...s}){super(s),this._c=t,this._values=[]}calc(t){if(1!==t.cols)throw new NeuralnetworkException("Invalid input.",[this,t]);const s=[...new Set(t.value)];this._c||(this._c=s.length);for(let t=0;t<s.length&&this._values.length<this._c;t++)this._values.indexOf(s[t])<0&&this._values.push(s[t]);const e=Matrix.zeros(t.rows,this._c);for(let s=0;s<t.rows;s++)e.set(s,this._values.indexOf(t.at(s,0)),1);return e}grad(t){return t.sum(1)}},NeuralnetworkLayers.less=class extends Layer{calc(...t){return this._i=t,this._o=t[0].copy(),this._o.map(((s,e)=>s<t[1].value[e])),this._o}},NeuralnetworkLayers.cond=class extends Layer{calc(...t){this._cond=t[0];const s=t[1],e=t[2];return this._o=new Matrix(this._cond.rows,this._cond.cols),this._o.map(((t,r)=>this._cond.value[r]?s.value[r]:e.value[r])),this._o}grad(t){const s=[null,t.copy(),t.copy()];return this._cond.forEach(((t,e)=>t?s[2].value[e]=0:s[1].value[e]=0)),s}},NeuralnetworkLayers.loss=class extends Layer{calc(t){return t}grad(){return new Matrix(1,1,1)}},NeuralnetworkLayers.mse=class extends NeuralnetworkLayers.loss{bind({supervisor:t}){this._t=t}calc(t){this._i=t;const s=t.copySub(this._t);return s.mult(s),new Matrix(1,1,s.mean())}grad(){const t=this._i.copySub(this._t);return t.div(2),t}},NeuralnetworkLayers.huber=class extends NeuralnetworkLayers.loss{bind({supervisor:t}){this._t=t}calc(t){this._i=t;const s=this._t.copySub(t);return s.map(Math.abs),this._cond=new Matrix(s.rows,s.cols,s.value.map((t=>t<1))),s.map(((t,s)=>this._cond.value[s]?.5*t*t:t-.5)),new Matrix(1,1,s.sum())}grad(){return this._bi=this._cond.copy(),this._bi.map(((t,s)=>t?this._i.value[s]-this._t.value[s]:Math.sign(this._i.value[s]-this._t.value[s]))),this._bi}};
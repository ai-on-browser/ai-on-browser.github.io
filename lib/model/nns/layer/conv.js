import Layer,{NeuralnetworkLayerException}from"./base.js";import Tensor from"../../../util/tensor.js";export default class ConvLayer extends Layer{constructor({kernel:i,channel:t=null,stride:e=null,padding:n=null,w:s=null,activation:h=null,l2_decay:_=0,l1_decay:a=0,activation_params:l={},channel_dim:r=-1,...o}){if(super(o),this._in_channel=null,this._out_channel=t,this._kernel=i,this._stride=e||1,this._padding=n||0,this._channel_dim=r,-1!==this._channel_dim&&1!==this._channel_dim)throw new NeuralnetworkLayerException("Invalid channel dimension.");this._w=null,this._wname=null,"string"==typeof s?this._wname=s:s&&(this._w=Tensor.fromArray(s),this._in_channel=this._w.sizes[1],this._out_channel||(this._out_channel=this._w.sizes[0])),this._activation=h,h&&(this._activation_func=Layer.fromObject({type:h,...l})),this._l2_decay=_,this._l1_decay=a}_index(i,t,e){return-1===this._channel_dim?[i,...e,t]:[i,t,...e]}calc(i){if(i.dimension<=2)throw new NeuralnetworkLayerException("Invalid input.");if(Array.isArray(this._kernel)||(this._kernel=Array(i.dimension-2).fill(this._kernel)),i.dimension!==this._kernel.length+2)throw new NeuralnetworkLayerException("Invalid kernel size",[this,i]);this._wname&&(this._w=this.graph.getNode(this._wname).outputValue,this._in_channel||(this._in_channel=this._w.sizes[1]),this._out_channel||(this._out_channel=this._w.sizes[0])),this._w||(this._in_channel=i.sizes[-1===this._channel_dim?i.dimension-1:1],this._out_channel||(this._out_channel=2*this._in_channel),this._w=Tensor.randn([this._out_channel,this._in_channel,...this._kernel])),this._i=i;const t=-1===this._channel_dim?1:2,e=[i.sizes[0],...this._kernel.map(((e,n)=>Math.ceil(Math.max(0,i.sizes[n+t]+2*this._padding-e)/this._stride)+1))];-1===this._channel_dim?e.push(this._out_channel):1===this._channel_dim&&e.splice(1,0,this._out_channel),this._o=new Tensor(e);for(let n=0;n<i.sizes[0];n++)for(let s=0;s<this._out_channel;s++){const h=Array(this._kernel.length).fill(0);do{let _=0;const a=Array(this._kernel.length).fill(0);do{const e=a.map(((i,t)=>h[t]*this._stride-this._padding+i));if(e.every(((e,n)=>0<=e&&e<i.sizes[n+t])))for(let t=0;t<this._in_channel;t++)_+=i.at(this._index(n,t,e))*this._w.at(s,t,...a);for(let i=0;i<a.length&&(a[i]++,!(a[i]<this._kernel[i]));i++)a[i]=0}while(a.some((i=>i>0)));this._o.set(this._index(n,s,h),_);for(let i=0;i<h.length&&(h[i]++,!(h[i]<e[i+t]));i++)h[i]=0}while(h.some((i=>i>0)))}return this._activation_func?this._activation_func.calc(this._o):this._o}grad(i){this._bo=i,this._activation_func&&(this._bo=this._activation_func.grad(i)),this._bi=new Tensor(this._i.sizes),this._dw=new Tensor(this._w.sizes);const t=-1===this._channel_dim?1:2;for(let i=0;i<this._i.sizes[0];i++)for(let e=0;e<this._out_channel;e++){const n=Array(this._kernel.length).fill(0);do{const s=Array(this._kernel.length).fill(0);do{const h=s.map(((i,t)=>n[t]*this._stride-this._padding+i));if(h.every(((i,e)=>0<=i&&i<this._i.sizes[e+t])))for(let t=0;t<this._in_channel;t++)this._bi.operateAt(this._index(i,t,h),(h=>h+this._w.at(e,t,...s)*this._bo.at(this._index(i,e,n)))),this._dw.operateAt([e,t,...s],(s=>s+this._i.at(this._index(i,t,h))*this._bo.at(this._index(i,e,n))));for(let i=0;i<s.length&&(s[i]++,!(s[i]<this._kernel[i]));i++)s[i]=0}while(s.some((i=>i>0)));for(let i=0;i<n.length&&(n[i]++,!(n[i]<this._o.sizes[i+t]));i++)n[i]=0}while(n.some((i=>i>0)))}return this._wname?[this._bi,{[this._wname]:this._dw}]:this._bi}update(i){this._wname||this._w.broadcastOperate(i.delta("w",this._dw),((i,t)=>i-t))}toObject(){return{type:"conv",w:this._wname||this._w?.toArray(),channel:this._out_channel,kernel:this._kernel,stride:this._stride,padding:this._padding,activation:this._activation,l2_decay:this._l2_decay,l1_decay:this._l1_decay,activation_params:this._activation_func?.toObject(),channel_dim:this._channel_dim}}}ConvLayer.registLayer();
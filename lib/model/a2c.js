import{RLEnvironmentBase,RLRealRange}from"../rl/base.js";import NeuralNetwork from"./neuralnetwork.js";class ActorCriticNet{constructor(t,e=20,s=[],a="sgd"){this._resolution=e,this._states=t.states,this._actions=t.actions,this._action_sizes=t.actions.map((t=>Array.isArray(t)?t.length:e)),this._layers=[{type:"input",name:"state"},...s,{type:"identity",name:"d"},{type:"full",out_size:1,name:"value"},{type:"full",out_size:this._action_sizes.reduce(((t,e)=>t*e),1),input:["d"],name:"actor"},{type:"softmax",name:"prob"},{type:"log",name:"log_prob"},{type:"input",name:"action"},{type:"mult",input:["log_prob","action"]},{type:"sum",axis:1,name:"action_log_prob"},{type:"mult",input:["log_prob","prob"]},{type:"sum",axis:1},{type:"mean"},{type:"negative",name:"entropy"},{type:"input",name:"reward"},{type:"sub",input:["reward","value"],name:"advantages"},{type:"power",n:2},{type:"mean",name:"value_loss"},{type:"detach",input:["advantages"],name:"detach_adv"},{type:"mult",input:["action_log_prob","detach_adv"]},{type:"mean",name:"action_gain"},{type:"mult",input:[.5,"value_loss"],name:"value_c"},{type:"mult",input:[.01,"entropy"],name:"entropy_c"},{type:"sub",input:["value_c","action_gain","entropy_c"]},{type:"mean"}],this._net=NeuralNetwork.fromObject(this._layers,null,a)}get_action(t){t=this._state_to_input(t);const e=this._net.calc([t],null,["prob"]).prob.toArray()[0];let s=Math.random();for(let t=0;t<e.length;t++)if(s-=e[t],s<0)return this._pos_action(t);return this._pos_action(0)}_state_to_input(t){const e=[];for(let s=0;s<t.length;s++)if(Array.isArray(this._states[s]))for(let a=0;a<this._states[s].length;a++)e.push(this._states[s][a]===t[s]?1:0);else e.push(t[s]);return e}get_score(t){if(t)return this._net.calc(t.map((t=>this._state_to_input(t))),null,["value"]).value.toArray();if(!this._states_data){const t=this._states.map((t=>t.toArray(this._resolution).length));this._states_data=[];const e=e=>{for(let s=0;s<e.length;s++){if(e[s]++,e[s]<t[s])return!0;e[s]=0}return!1},s=Array(this._states.length).fill(0);do{this._states_data.push([].concat(s))}while(e(s))}const e=this._net.calc(this._states_data,null,["prob"]).prob.toArray(),s=[],a=this._states.length;for(let t=0;t<this._states_data.length;t++){let i=s;for(let e=0;e<a-1;e++)i[this._states_data[t][e]]||(i[this._states_data[t][e]]=[]),i=i[this._states_data[t][e]];i[this._states_data[t][a-1]]=e[t]}return s}_action_pos(t){let e=0;for(let s=0;s<t.length;s++)if(e*=this._action_sizes[s],Array.isArray(this._actions[s]))e+=this._actions[s].indexOf(t[s]);else{if(!(this._actions[s]instanceof RLRealRange))throw"Not implemented";e+=this._actions[s].indexOf(t[s],this._resolution)}return e}_pos_action(t){const e=[];for(let s=this._action_sizes.length-1;s>=0;s--){const a=t%this._action_sizes[s];if(t=Math.floor(t/this._action_sizes[s]),Array.isArray(this._actions[s]))e.unshift(this._actions[s][a]);else{if(!(this._actions[s]instanceof RLRealRange))throw"Not implemented";e.unshift(this._actions[s].toArray(this._resolution)[a])}}return e}update(t,e,s,a,i){t=t.map((t=>this._state_to_input(t))),e=e.map((t=>{const e=this._action_pos(t),s=Array(this._action_sizes.reduce(((t,e)=>t*e),1)).fill(0);return s[e]=1,s}));return this._net.fit({state:t,action:e,reward:s},null,1,a,i)[0]}}export default class A2CAgent{constructor(t,e,s,a,i){this._net=new ActorCriticNet(t,e,a,i),this._procs=s,this._env=t,this._advanced_step=5,this._gamma=.99,this._states=[];for(let t=0;t<this._procs;t++)this._states[t]=this._env.reset()}terminate(){}get_score(){return this._net.get_score()}get_action(t){return this._net.get_action(t)}update(t,e,s){const a=[],i=[],n=[],o=[],r=[],_=this._env.state();for(let t=0;t<this._advanced_step;t++)for(let t=0;t<this._procs;t++){const e=this._net.get_action(this._states[t]),s=this._env.test(this._states[t],e);(a[t]||=[]).push(e),(i[t]||=[]).push(this._states[t]),(n[t]||=[]).push(s.state),(o[t]||=[]).push(s.reward),(r[t]||=[]).push(s.done),s.done?this._states[t]=this._env.reset():this._states[t]=s.state}this._env.setState(_);const h=this._net.get_score(n.map((t=>t[t.length-1]))),l=[];for(let t=0;t<this._procs;t++)l[t]=[],l[t][this._advanced_step-1]=h[t][0];for(let t=this._advanced_step-2;t>=0;t--)for(let e=0;e<this._procs;e++)l[e][t]=o[e][t],r[e][t]||(l[e][t]+=l[e][t+1]*this._gamma);return this._net.update(i.flat(1),a.flat(1),l.flat(1).map((t=>[t])),e,s)}}
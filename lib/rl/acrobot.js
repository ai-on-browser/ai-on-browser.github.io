import{RLRealRange,RLEnvironmentBase}from"./base.js";export default class AcrobotRLEnvironment extends RLEnvironmentBase{constructor(){super(),this._theta1=0,this._theta2=0,this._dtheta1=0,this._dtheta2=0,this._link_len1=1,this._link_len2=1,this._link_mass1=1,this._link_mass2=1,this._link_com_pos1=.5,this._link_com_pos2=.5,this._moi=1,this._max_vel1=4*Math.PI,this._max_vel2=9*Math.PI,this._g=9.8,this._dt=.1,this._max_step=200,this._reward={goal:0,step:-1,fail:0}}get actions(){return[[-1,0,1]]}get states(){return[new RLRealRange(-Math.PI,Math.PI),new RLRealRange(-Math.PI,Math.PI),new RLRealRange(-this._max_vel1,this._max_vel1),new RLRealRange(-this._max_vel2,this._max_vel2)]}set reward(t){this._reward={goal:0,step:-1,fail:0},"achieve"===t&&(this._reward={goal:0,step:-1,fail:0})}reset(){return super.reset(),this._theta1=.2*Math.random()-.1,this._theta2=.2*Math.random()-.1,this._dtheta1=.2*Math.random()-.1,this._dtheta2=.2*Math.random()-.1,this.state()}state(){return[this._theta1,this._theta2,this._dtheta1,this._dtheta2]}setState(t){this._theta1=t[0],this._theta2=t[1],this._dtheta1=t[2],this._dtheta2=t[3]}test(t,s){let[h,a,e,i]=t;const _=s[0],n=this._link_mass1,r=this._link_mass2,l=this._link_len1,o=this._link_com_pos1,m=this._link_com_pos2,M=this._moi,d=this._moi,c=this._g,R=n*o**2+r*(l**2+m**2+2*l*m*Math.cos(a))+M+d,I=r*(m**2+l*m*Math.cos(a))+d,P=r*m*c*Math.cos(h+a-Math.PI/2),p=(_+I/R*(-r*l*m*i**2*Math.sin(a)-2*r*l*m*i*e*Math.sin(a)+(n*o+r*l)*c*Math.cos(h-Math.PI/2)+P)-r*l*m*e**2*Math.sin(a)-P)/(r*m**2+d-I**2/R),v=-(I*p+P)/R,x=(t,s,h)=>t<s?s:t>h?h:t;h+=this._dt*e,h<-Math.PI&&(h+=2*Math.PI),h>Math.PI&&(h-=2*Math.PI),a+=this._dt*i,a<-Math.PI&&(a+=2*Math.PI),a>Math.PI&&(a-=2*Math.PI),e=x(e+this._dt*v,-this._max_vel1,this._max_vel1),i=x(i+this._dt*p,-this._max_vel2,this._max_vel2);const g=this.epoch>=this._max_step,w=-Math.cos(h)-Math.cos(a+h)>1||g;return{state:[h,a,e,i],reward:g?this._reward.fail:w?this._reward.goal:this._reward.step,done:w}}}
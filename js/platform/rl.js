import{BasePlatform}from"./base.js";import EmptyRLEnvironment from"../../lib/rl/base.js";import LinePlotter from"../renderer/util/lineplot.js";import GameManager from"./game/base.js";import RLRenderer from"../renderer/rl.js";const LoadedRLEnvironmentClass={},AIEnv={MD:["grid","cartpole","mountaincar","acrobot","pendulum","maze","blackjack","waterball","breaker"],GM:["reversi","draughts","gomoku"]};export default class RLPlatform extends BasePlatform{constructor(t,e,s){super(t,e),this._type="",this._epoch=0,this._env=new EmptyRLEnvironment,this._game=null,this._is_updated_reward=!1,this._cumulativeReward=0,this._rewardHistory=[],this._renderer.forEach((t=>t.terminate())),this._renderer=[new RLRenderer(e)],this._load_env().then((()=>s(this)));const i=this.setting.task.configElement;i.appendChild(document.createTextNode("Environment"));const r=document.createElement("select");r.name="env",r.onchange=()=>{this._plotter&&this._plotter.terminate(),this.setting.rl.configElement.replaceChildren(),this._type=r.value,this.setting.vue.pushHistory(),this._load_env().then((()=>{this.setting.ml.refresh()}))},r.appendChild(document.createElement("option"));for(const t of AIEnv[this.task]){const e=document.createElement("option");e.value=t,e.innerText=t,r.appendChild(e)}i.appendChild(r),this._infoelm=document.createElement("div"),this._infoelm.style.color="red",i.appendChild(this._infoelm)}get params(){return{env:this._type}}set params(t){t.env&&this._type!==t.env&&(this._type=t.env,this._load_env().then((()=>{const t=this.setting.task.configElement.querySelector("[name=env]");t&&(t.value=this._type)})))}get epoch(){return this._epoch}get actions(){return this._env.actions}get states(){return this._env.states}get type(){return this._type}get env(){return this._env}set reward(t){this._env.reward=t}async _load_env(){if(this._env&&this._env.close(),LoadedRLEnvironmentClass[this.type])this._env=new LoadedRLEnvironmentClass[this.type](this._renderer[0].width,this._renderer[0].height),this.init();else{if(""!==this.type)return import(`../../lib/rl/${this.type}.js`).then((t=>{this._env=new t.default(this._renderer[0].width,this._renderer[0].height),LoadedRLEnvironmentClass[this.type]=t.default,this.init()}));this._env=new EmptyRLEnvironment}}cumulativeReward(t){return this._cumulativeReward}rewardHistory(t){return this._rewardHistory}init(){this._game&&(this._game.terminate(),this._game=null),"GM"===this.task&&""!==this._type&&(this._game=new GameManager(this)),this._infoelm.innerText="",this._loss&&(this._loss.terminate(),this._loss=null),this._renderer.forEach((t=>t.init()))}reset(...t){return this._epoch=0,this._agents&&this._agents.some(((e,s)=>e!==t[s]))&&(this._is_updated_reward=!1,this._rewardHistory=[],this._loss&&(this._loss.terminate(),this._loss=null)),this._game&&""!==this._manager._modelname?(this._game.terminate(),this._game=null):this._game||""!==this._manager._modelname||(this._game=new GameManager(this)),"GM"===this.task&&""!==this._manager._modelname&&["","gomoku","reversi"].indexOf(this._type)<0?this._infoelm.innerText="Currently, only the gomoku and the reversi environment is available as a learning environment.":this._infoelm.innerText="",this._agents=t,this._is_updated_reward&&this._rewardHistory.push(this._cumulativeReward),this._is_updated_reward=!1,this._cumulativeReward=0,this._plotter&&(this._plotter.printEpisode(),this._plotter.printStep(),this._plotter.plotRewards()),this._env.reset()}render(t){this._renderer.forEach((e=>e.render(t)))}terminate(){this._plotter?.terminate(),this._game?.terminate(),this.setting.rl.configElement.replaceChildren(),this.setting.task.configElement.replaceChildren(),this._env.close(),this._loss&&(this._loss.terminate(),this._loss=null),super.terminate()}state(t){return this._env.state(t)}step(t,e){this._epoch++;const s=this._env.step(t,e);return this._is_updated_reward=!0,this._cumulativeReward+=s.reward,this._plotter&&(this._plotter.printEpisode(),this._plotter.printStep(),this._plotter.plotRewards()),s}test(t,e,s){return this._env.test(t,e,s)}sample_action(t){return this._env.sample_action(t)}plotRewards(t){this._plotter=new RewardPlotter(this,t),this._plotter.printEpisode(),this._plotter.printStep(),this._plotter.plotRewards()}plotLoss(t){this._loss||(this._loss=new LinePlotter(this.setting.footer)),this._loss.add(t)}}class RewardPlotter{constructor(t,e){this._platform=t,this._r=e.select("span.reward_plotarea"),0===this._r.size()&&(this._r=e.append("span").classed("reward_plotarea",!0)),this._r.style("white-space","nowrap"),this._loss=null,this._plot_rewards_count=1e4,this._plot_smooth_window=20}terminate(){this._r.remove()}lastHistory(t=0){if(t<=0)return this._platform._rewardHistory;const e=this._platform._rewardHistory.length;return this._platform._rewardHistory.slice(Math.max(0,e-t),e)}printEpisode(){let t=this._r.select("span[name=episode]");0===t.size()&&(t=this._r.append("span").attr("name","episode")),t.text(" Episode: "+(this.lastHistory().length+1))}printStep(){let t=this._r.select("span[name=step]");0===t.size()&&(t=this._r.append("span").attr("name","step")),t.text(" Step: "+this._platform.epoch)}plotRewards(){this._loss||(this._loss=new LinePlotter(this._r.node())),this._loss.setValues({"":this.lastHistory(this._plot_rewards_count)})}}